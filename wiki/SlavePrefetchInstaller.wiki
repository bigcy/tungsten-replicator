#summary Interface design for slave pre-fetching
= Slave Prefetch Design and Operation =
<wiki:toc max_depth="4" />
== Overview ==
Slave pre-fetching is a feature that reads ahead of the slave applier, and warms up the pages needed by the applier by converting THL updates into selects and executing them a few seconds before the slave applies the change. This way, the page is already in memory by the time the change is applied.

== Implementation ==
The pre-fetcher is a replicator service that can be installed in two ways: either as a service to an already existing replicator or as a separate replicator. This second one, while likely less efficient, is possibly more common, as it can be used to boost a Tungsten Enterprise slave or (eventually) to speed up a MySQL native replication slave by reading the relay logs and applying from them.
Either way, the pre-fetching replicator service will not write anywhere in the database, will not have its own service database, and will borrow connecting credentials from another replication service.

=== Pipeline for Pre-fetching ===

 * Connection parameters will be taken from the slave that needs to be boosted. It should be on the same host, for efficiency reasons;
 * There should be a new role, *prefetch* that will set the defaults for this case.
 *  The pipeline will be a simple *thl-to-q,q-to-dbms*.
 * the THL directory must be the same as the slave being boosted;
 * the  operational mode for the THL must be read-only
 * There are three properties that tune the service, related to
   * time to read ahead
   * sleep time (purpose required)
   * events to skip

=== Configuration Description ===

The snippet below is an example of the changes made to the static properties file.  It shows how to define a prefetch pipeline, configure, the prefetch applier, and configure the supplemental prefetch filter, which controls the rate at which transactions are fed to the parallel queue in the second stage.  

{{{
#
# Connection parameters are the ones of the slave being boosted.
#
replicator.global.db.host=127.0.0.1
replicator.global.db.port=3306
replicator.global.db.user=tungsten
replicator.global.db.password=secret

replicator.global.extract.db.host=127.0.0.1
replicator.global.extract.db.port=3306
replicator.global.extract.db.user=tungsten
replicator.global.extract.db.password=secret

#
# Define a prefetch pipeline as follows. 
#
replicator.role=prefetch

replicator.pipelines=prefetch
replicator.pipeline.prefetch=thl-to-q,q-to-dbms
replicator.pipeline.slave.stores=thl,parallel-queue

replicator.stage.thl-to-q=com.continuent.tungsten.replicator.pipeline.SingleThreadStageTask
replicator.stage.thl-to-q.extractor=thl-extractor
replicator.stage.thl-to-q.applier=parallel-q-applier
replicator.stage.thl-to-q.blockCommitRowCount=${replicator.global.buffer.size}
replicator.stage.thl-to-q.filters=prefetch

replicator.stage.q-to-dbms=com.continuent.tungsten.replicator.pipeline.SingleThreadStageTask
replicator.stage.q-to-dbms.extractor=parallel-q-extractor
replicator.stage.q-to-dbms.applier=prefetch
replicator.stage.q-to-dbms.filters=mysqlsessions,pkey,bidiSlave
replicator.stage.q-to-dbms.taskCount=${replicator.global.apply.channels}
replicator.stage.q-to-dbms.blockCommitRowCount=${replicator.global.buffer.size}

# 
# Define the THL location and set read-only flag as follows. 
#
replicator.store.thl.log_dir=/same/as/the/boosted/slave
replicator.store.thl.readOnly=true

#
# Define the prefetch applier as follows. 
#
replicator.applier.prefetch=com.continuent.tungsten.replicator.applier.JdbcPrefetcher
replicator.applier.prefetch.url=jdbc:mysql:thin://${replicator.global.db.host}:${replicator.global.db.port}/
replicator.applier.prefetch.user=${replicator.global.db.user}
replicator.applier.prefetch.password=${replicator.global.db.password}

# 
# Define the prefetch filter as follows. 
#
replicator.filter.prefetch=com.continuent.tungsten.replicator.filter.PrefetchFilter
replicator.filter.prefetch.url=jdbc:mysql:thin://${replicator.global.db.host}:${replicator.global.db.port}/
replicator.filter.prefetch.aheadMaxTime=120
replicator.filter.prefetch.sleepTime=200
replicator.filter.prefetch.warmUpEventCount=200
}}}

All other property file values remain the same. 

=== Pre-Fetch Query Generation ===

Pre-fetch may require multiple queries to read data pages for a single update operation.  Let's assume the following example table.  

{{{
CREATE TABLE `appuser` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `last_name` varchar(128) DEFAULT NULL,
  `first_name` varchar(128) DEFAULT NULL,
  `office_id` int(11) DEFAULT NULL,
  `login` varchar(32) DEFAULT NULL,
  `salary` int(11) DEFAULT NULL,
  `creation_date` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `appuser_idx_name` (`last_name`,`first_name`),
  KEY `appuser_idx_login` (`login`),
  KEY `appuser_fk_1` (`office_id`),
  CONSTRAINT `appuser_fk_1` FOREIGN KEY (`office_id`) REFERENCES `office` (`id`) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=latin1
}}}

To pre-fetch properly on this table we need to generate queries to fetch the following kinds of pages into the buffer cache: 

# Primary keys and leaf rows.  We need to select each row that will be written into memory.  
# Secondary index pages.  We need to force reading of pages on affected secondary indexes such as appuser_idx_name.  These pages may be used to find data in the first place and will certainly need to be present if they are updated.  This can be accomplished by issuing queries that use the secondary index as a covering index.  
# Foreign keys.  Foreign key constraints require that affected primary key pages on referenced tables should be available. 

The next three subsections describe how to generate appropriate prefetch queries. 

==== Pre-fetch for INSERT ====

We can prefetch on INSERT statements as follows.  Assume the following sample statement: 

{{{
insert into appuser 
  (last_name, first_name, office_id, login, salary, creation_date)   
     values ('smith', 'bob', 23, 'bobsmith', 25000, now());
}}}

  # Generate a SELECT on the primary key, if known.  This loads the page that will receive the row.  For auto_increment keys like the sample this is not possible.
  # If the INSERT uses a SELECT to fetch data from another table, execute that SELECT statement. 
  # Issue covering queries on all matching indexes, for example: {{{SELECT count(*) from appuser force index(appuser_idx_login) where login='bobsmith'}}}
  # Issue queries to fetch foreign key values on their original tables, for example:  {{{SELECT id from office where id=23}}}

==== Pre-fetch for UPDATE ====

We can prefetch on UPDATE statements as follows.  Assume the following update statement: 

{{{
update appuser set last_name='brown' where id=352
}}}

  # Generate a SELECT on the update where clause. 
  # If the UPDATE uses a sub-select to fetch data from another table, execute that SELECT statement. 
  # Issue covering queries on all matching indexes, for example: {{{SELECT count(*) from appuser force index(appuser_idx_name) where last_name='brown'}}}
  # Issue queries to fetch affected foreign key values on their original tables, for example:  {{{SELECT id from office where id=23}}}

Update pre-fetch is somewhat inefficiently when using statement replication as we cannot see the affected values easily. 

==== Pre-fetch for DELETE ====

We can prefetch on DELETE statements as follows.  Assume the following statement: 

{{{
delete from appuser where id=352
}}}

  # Generate a SELECT on the where clause used to delete rows.  Record the data received from the query to generate additional queries. 
  # Issue covering queries on all matching indexes, for example: {{{SELECT count(*) from appuser force index(appuser_idx_name) where last_name='smith' and first_name='bob'}}}
  # If there are cascading deletes due to foreign key relationships we should presumably issue selects on those tables as well using the same logic. 

== User interface ==

The new feature requires the ability of installing three different topologies of pre-fetcher

 * stand-alone replicator reading from THL
 * stand-alone replicator reading from relay logs
 * additional service of existing replicator

Note:  Current implementations focus on the first case, namely downloading from the slave THL via TCP/IP. 

=== Common properties ===
In all the configurations, users can tune the pre-fetching service with the following installation options:

|| Install option || Meaning ||
|| prefetch-enabled || If true set the service up as a prefetch applier ||
|| prefetch-time-ahead || Max seconds prefetch can precede the slave applier ||
|| prefetch-sleep-time || Number of milliseconds to sleep when the prefetch applier gets too far ahead ||
|| prefetch-warmup-event-count || Events to skip when applier first goes online ||
|| prefetch-schema || Catalog schema of slave for which we are prefetching ||

=== Installation Command to Read from Remote THL ===

The following command shows a typical command to prefetch from a slave by downloading from the slave THL.  This command installs a completely separate replicator process and can be used for both Tungsten 2.0 as well as Tungsten 1.3 replicators. 

{{{
$ tools/tungsten-installer --master-slave -a \
  --home-directory=$TUNGSTEN_HOME \
  --prefetch-enabled=true \
  --prefetch-schema=tungsten \
  --prefetch-max-ahead-time=120 \
  --cluster-hosts=logos2 \
  --datasource-port=3306 \
  --datasource-user=tungsten \
  --datasource-password=secret \
  --master-host=logos2 \
  --master-thl-port=2112 \
  --thl-port=2114 \
  --rmi-port=10002 \
  --service-name=slave_prefetch \
  --channels=10 \
  --start-and-report
}}}

In this configuration 'master' refers to the slave for which this service acts as a prefetcher.  Note that the prefetch service uses offset (i.e. non-default) THL and RMI ports to prefetch clashes with the slave.  

=== stand-alone replicator reading from relay logs ===

{{{
./tools/tungsten-installer
    --direct
    --prefetch-enabled=true
    --master-host
    --master-port
    --master-user
    --master-password
   --slave-host
   --slave-port
   --slave-user
   --slave-password
}}}

=== additional service of existing replicator ===

{{{
./tools/configure --home-directory=/opt/continuent
/opt/continuent/tools/configure-service
    -C
    --role=slave
    --prefetch-enabled=true
    --local-service-name
    --service-type=remote
    --thl-directory
}}}