#summary Tungsten Replicator cookbook
#labels Featured,Phase-Deploy
<wiki:toc max_depth="4" />
= Tungsten Replicator Cookbook =

This is a collection of practical recipes to deal with Tungsten Replicator.

== 1. Installation ==

=== 1.1 Get the replicator ===

All the recipes about installation require that you get Tungsten Replicator binaries. This recipe explains how to do it once for ever.

 # Determine which is the latest version. The latest stable version is the one featured on [http://code.google.com/p/tungsten-replicator/ Tungsten Replicator project page]
 # If you want the latest release, which probably has more features, more bug fixes, and possibly more unknown bugs, you may get the very latest binaries [http://s3.amazonaws.com/files.continuent.com/builds/nightly/tungsten-2.0-snapshots/index.html from the build server].
 # Download the replicator
 # Create a temporary directory. This is *not* the directory where you want to install Tungsten. You will use it only to launch the installation command. 
 # Expand the tarball
 # Get inside the newly created directory
 # We refer to this directory as the *release directory*
 # Now you can follow the directions from another recipe.

=== 1.2 Install a master / slave cluster ===

 # make sure that all the hosts meet the [https://s3.amazonaws.com/releases.continuent.com/doc/replicator-2.0.4/html/Tungsten-Installation-Guide-mysql/content/ch05.html requirements]
 # create a directory where you want to install the replicator. We refer to this directory as the * Tungsten home directory*;
 # Get the replicator binaries using recipe 1.1
 # Run the following command, after changing the directory and host names to match your environment.

{{{
  TUNGSTEN_HOME=$HOME/replication
  MASTER=m1.mynetwork.com
  SLAVE1=m3.mynetwork.com
  SLAVE2=m3.mynetwork.com
  ./tools/tungsten-installer \
    --master-slave \
    --master-host=$MASTER \
    --datasource-user=MYUSER \
    --datasource-password=MYPWD \
    --service-name=dragon \
    --home-directory=$TUNGSTEN_HOME \
    --cluster-hosts=$MASTER,$SLAVE1,$SLAVE2 \
    --start-and-report
}}}

This command takes several defaults into account.
It assumes that MySQL is installed in {{{/var/lib/mysql/}}}, that the server uses port {{{3306}}}, and that the binary logs are in the data directory. We use these values because they are the ones used by RPM installers.
If you use different values, please see recipe 1.3.


=== 1.3 Install a master slave directory with customized parameters ===

If the defaults used in recipe 1.2 are not convenient, you can instruct the replicator to use paths and ports that describe your server.

You should add these options to the installation command.

{{{
  --datasource-port=${MASTER_MYSQL_PORT} \
  --datasource-log-directory=/path/to/your/binary/logs \
  --datasource-log-pattern=my-bin
}}}


=== 1.4 Install more than one Tungsten Replicator in one host ===

You may install more than one Tungsten Replicator in the same host.
One good reason for doing it may be because you want to test several servers at once, or because you have more MySQL servers in the same host and they need to replicate from different masters.
In the first case, you may want to have a look at [http://code.google.com/p/tungsten-toolbox/ Tungsten sandbox]. But if you want to do that on your own, you need to make sure that there is no overlapping of three base elements in the replicator: 

 * the *THL directory*, which is the place where the Transaction history logs are stored. This directory contains one directory for every service. It is important that you don't use two replicators with the same service name pointing at this directory.
 * The *THL port*. This is the port used by the replicator to send the transaction records.
 * The *RMI port*. This port is used to send JMX messages that the replicator uses for its own functioning.

For example:
{{{
  --thl-directory=/path/to/THL/files \
  --thl-port=22000 \
  --rmi-port=10500 \
}}}

=== 1.5 Install a direct slave with parallel replication ===

Direct slave replication is a quick method to set replication in a slave, without installing a master replicator.
It works by establishing a connection with the master, fetching the binary logs locally, and creating a THL stream with that.
The additional effort of creating relay logs is then compensated by using parallel replication.

This installation assumes that the slave is not running native MySQL replication. For that case, see recipe 1.6.

{{{
  TUNGSTEN_HOME=$HOME/replication
  MASTER=m1.mynetwork.com
  SLAVE1=m2.mynetwork.com
  ./tools/tungsten-installer \
    --direct \
    --master-host=$MASTER \
    --slave-host=$SLAVE \
    --master-user=tungsten \
    --slave-user=tungsten \
    --master-password=secret \
    --slave-password=secret \
    --service-name=mydirect \
    --channels=10 \
    --home-directory=$TUNGSTEN_BASE \
    --svc-parallelization-type=disk \
    --start-and-report 
}}}

Notice that you need to pass connection credentials for both the master and the slave. As in regular master/slave replication, there are defaults, which you can override using the following options (defaults in brackets)

{{{
  --master-host
  --master-port [3306]
  --master-user
  --master-password
  --master-log-directory  [/var/lib/mysql]
  --master-log-pattern    [mysql-bin]
}}}

=== 1.6 taking over replication from a MySQL slave in direct mode ===

In the previous recipe, we have shown how to start replication from a MySQL master, without a replicator on the master side. 
If the slave is already using MySQL native replication with the intended master, you can take over from the native replication stream simply adding to your installation command
{{{
--native-slave-takeover 
}}}

With this command, Tungsten stops the MySQL slave, gets the binlog file and position from the slave status, and starts replicating from that point.

When the replicator goes offline, it will send a "CHANGE MASTER TO" command to the slave to update log file and position, so that you can continue moving data either with Tungsten or with native replication.

=== 1.7 Install bi-directional replication ===

To install multiple replication services on two nodes, you need first to install the master service. This is similar to master-slave installation, with the difference that we are not installing any slaves. Only masters.

{{{
TUNGSTEN_HOME=$HOME/replication
MASTER1=m1.mynetwork.com
MASTER1=m2.mynetwork.com

./tools/tungsten-installer \
    --master-slave \
    --master-host=$MASTER1 \
    --datasource-user=tungsten \
    --datasource-password=secret \
    --service-name=charlie \
    --home-directory=$TUNGSTEN_HOME \
    --cluster-hosts=$MASTER1 \
    --start-and-report

  ./tools/tungsten-installer \
    --master-slave \
    --master-host=$MASTER2 \
    --datasource-user=tungsten \
    --datasource-password=secret \
    --service-name=delta \
    --home-directory=$TUNGSTEN_HOME \
    --cluster-hosts=$MASTER2 \
    --start-and-report

}}}

You run the above commands from the *release directory*. After that, the *Tungsten home directory* is populated, and the following commands need to run from there.

What we need to do is creating, on each host, a slave service for the corresponding master on the other host. Thus, since we have "charlie" on MASTER1 and "delta" on MASTER2, we will create a slave service "delta" on MASTER1 and "charlie" on MASTER2.

{{{
TUNGSTEN_TOOLS=$TUNGSTEN_HOME/tungsten/tools

$TUNGSTEN_TOOLS/configure-service \
   --host $MASTER1 \
   -C -q \
   --local-service-name=charlie \
   --role=slave \
   --service-type=remote \
   --datasource=m1_mynetwork_com \
   --master-thl-host=$MASTER2 \
   --svc-start delta

$TUNGSTEN_TOOLS/configure-service 
  --host $MASTER2 \
  -C -q \
    --local-service-name=delta \
    --role=slave \
    --service-type=remote \
    --datasource=m2_mynetwork_com
    --master-thl-host=$MASTER1 \
    --svc-start charlie
}}}

The datasource name is the name of the local hostname, with dots replaced by underscores. (Note to self: this needs to become a bit easier to deal with).

=== 1.8 Install bi-directional replication with additional slave ===

The recipe is similar to 1.7.
Assuming that we have a candidate slave m3.mynetwork.com, which we want to be slave of m2, what we will do is simply add this information to the second installation command:

{{{
SLAVE1=m3.mynetwork.com

  ./tools/tungsten-installer \
    --master-slave \
    --master-host=$MASTER2 \
    --datasource-user=tungsten \
    --datasource-password=secret \
    --service-name=delta \
    --home-directory=$TUNGSTEN_HOME \
    --cluster-hosts=$MASTER2,SLAVE1 \
    --start-and-report
}}}

The only difference is SLAVE1 in the --cluster-hosts list, and Tungsten will take care of the rest.

=== 1.9 Install a three masters replication ===

This recipe is left as an exercise for readers who have successfully managed recipe 1.10.

=== 1.10 Install a four masters replication ===

You want to install four nodes, in such a way that each node is a master, and each one receives changes from all other nodes.

As in bi-directional replication, you install the master services first.

{{{
TUNGSTEN_HOME=$HOME/replication
MASTER1=m1.mynetwork.com
MASTER1=m2.mynetwork.com
MASTER3=m3.mynetwork.com
MASTER4=m4.mynetwork.com

./tools/tungsten-installer \
   --master-slave \
   --master-host=$MASTER1 \
   --datasource-user=tungsten \
   --datasource-password=secret \
   --service-name=alpha \
   --home-directory=/home/tungsten/installs/four_masters \
   --cluster-hosts=$MASTER1 --start-and-report

./tools/tungsten-installer \
   --master-slave \
   --master-host=$MASTER2 \
   --datasource-user=tungsten \
   --datasource-password=secret \
   --service-name=alpha \
   --home-directory=/home/tungsten/installs/four_masters \
   --cluster-hosts=$MASTER2 --start-and-report

./tools/tungsten-installer \
   --master-slave \
   --master-host=$MASTER3 \
   --datasource-user=tungsten \
   --datasource-password=secret \
   --service-name=alpha \
   --home-directory=/home/tungsten/installs/four_masters \
   --cluster-hosts=$MASTER3 --start-and-report

./tools/tungsten-installer \
   --master-slave \
   --master-host=$MASTER4 \
   --datasource-user=tungsten \
   --datasource-password=secret \
   --service-name=alpha \
   --home-directory=/home/tungsten/installs/four_masters \
   --cluster-hosts=$MASTER4 --start-and-report
}}}

Next, you will install three slave services for each master.

{{{
TUNGSTEN_TOOLS=$TUNGSTEN_HOME/tungsten/tools

# MASTER 1

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER1 \
  --datasource=m1_mynetwork_com \
  --local-service-name=alpha \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER2 \
  --svc-start bravo

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER1 \
  --datasource=m1_mynetwork_com \
  --local-service-name=alpha \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER3 \
  --svc-start charlie

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER1 \
  --datasource=m1_mynetwork_com \
  --local-service-name=alpha \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER4 \
  --svc-start delta
}}}

Let's see master 2 

{{{
# MASTER 2

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER2 \
  --datasource=m2_mynetwork_com \
  --local-service-name=bravo \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER1 \
  --svc-start alpha

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER2 \
  --datasource=m2_mynetwork_com \
  --local-service-name=bravo \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER3 \
  --svc-start charlie

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER2 \
  --datasource=m2_mynetwork_com \
  --local-service-name=bravo \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER4 \
  --svc-start delta
}}}

And master 3:

{{{
# MASTER 3

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER3 \
  --datasource=m3_mynetwork_com \
  --local-service-name=charlie \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER1 \
  --svc-start alpha

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER3 \
  --datasource=m3_mynetwork_com \
  --local-service-name=charlie \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER2 \
  --svc-start bravo

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER4 \
  --datasource=m3_mynetwork_com \
  --local-service-name=bravo \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER4 \
  --svc-start delta
}}}

And finally master 4:

{{{
# MASTER 4

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER4 \
  --datasource=m4_mynetwork_com \
  --local-service-name=delta \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER1 \
  --svc-start alpha

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER4 \
  --datasource=m4_mynetwork_com \
  --local-service-name=bravo \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER2 \
  --svc-start bravo

$TUNGSTEN_TOOLS/configure-service \
  -C --quiet \
  --host=$MASTER4 \
  --datasource=m4_mynetwork_com \
  --local-service-name=delta \
  --role=slave \
  --service-type=remote \
  --release-directory=$TUNGSTEN_HOME/tungsten \
  --master-thl-host=$MASTER3 \
  --svc-start charlie
}}}

The procedure is longish, but once you get the gist of it you will be able to make a loop instead of coding these commands manually.

=== 1.11 Modify one or more properties with the installer ===

Tungsten Replicator gets its configuration from a file called static-SERVICE_NAME.properties, located $TUNGSTEN_HOME/tungsten/tungsten-replicator/conf/.
This file can be edited with a regular text editor. If you know what you are doing, you can fine tune the replicator to your will.
The procedure is not painless. You need to install the replicator first, then edit the file, then eventually restart the replicator.

This procedure is difficult to script, and it is especially inconvenient when the changed property needs to be there right when the replicator starts.

To your help, there is an option of {{{tungsten-installer}}}, which allows you to change any property in the properties file.

For example, let's suppose that you don;t want the replicator to go ONLINE automatically when it starts. This behavior is controlled by a property called {{{replicator.auto_enable}}}, which is true by default. Of course, if you install the replicator with the --start option, you won't get a chance of modifying the property, because the replicator will be already online.

To achieve your purpose, you will add this option to the installation command:
{{{
    --property=replicator.auto_enable=false
}}}

=== 1.12 Add one slave to an existing master ===

The procedure is almost the same used to create a master-slave cluster. You use a similar command, with {{{--master-slave}}} and {{{--master-host}}} as in the full cluster installation command. The difference is that the {{{--cluster-hosts}}} list will only contain the slave host. Tungsten will do the right thing.

=== 1.13 Start a master service with a given binlog and position ===

The easiest way of starting the master service at a given binlog file and position is by using 

{{{ --master-log-file=mysql-bin.000045 --master-log-pos=10292 }}}

(Note: there is a problem with this procedure as documented in  [http://code.google.com/p/tungsten-replicator/issues/detail?id=216 Issue#216].

If the replicator has already been installed and we want to start replicating from a given binlog file and position, we can do this:

{{{
    trepctl -host host_name -service service_name offline 
    trepctl -host host_name -service service_name online -from-event 000045:10292
}}}
Notice that we don't give the complete binlog file name, but only the extension. The number after the colon is the position.

== 2. Administration ==

=== 2.1 Check replication status ===

=== 2.2 Check replication status ===

=== 2.3 Suspend and resume replication ===

=== 2.4 Inspect Transaction History Logs ===

=== 2.5 Check parallel replication status ===

==== 2.5.1 Shards ====

==== 2.5.2 Tasks ====

==== 2.5.3 Stores ====