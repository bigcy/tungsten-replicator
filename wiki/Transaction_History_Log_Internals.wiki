#summary THL Architecture, Implementation, and Detailed Management

= Overview =

The Transaction History Log, or THL, provides persistent storage of transactions.  It enables very fast transfer of transactions between locations while at the same time preventing data loss due to failures of hosts, processes, and DBMS software. 

= Architecture =

== Embedded, Queue-Based Model ==

The THL functions as an embedded database within the replicator process.  It also runs inside the *thl* utility, which is a simple command-line tool to read the log.  The log files are protected by a file lock that permits multiple processes from writing to the log at the same time.  

The THL is a log and therefore differs from traditional databases in the following ways. 

  # The THL is a queue.  It is is optimized for reading and writing sequentially.  A single thread  writes log records.  Any number of threads can read records.  The API is optimized to deliver written records quickly to waiting readers in a queue-like fashion. 
  # THL records are immutable.  Once written, THL records do not change. 
  # No buffer cache.  The THL currently depends on OS-level buffering.  It does not attempt to maintain its own page cache.  

In other respects the THL behaves much like a pocket DBMS such as Derby or SQLLite, albeit without using SQL.  THL storage is self-maintaining.  There is a simple cursor-like API to seek to a specific position and step through records.  

== Log Organization ==

=== File Layout ===

Log files are stored in a single log directory, which is specified by the THL logDir parameter.  The following listing shows typical log file contents: 

{{{
-rw-r--r-- 1 tungsten tungsten         0 2011-06-28 22:01 disklog.lck
-rw-r--r-- 1 tungsten tungsten 100000231 2011-06-28 22:15 thl.data.0000000001
-rw-r--r-- 1 tungsten tungsten 100006532 2011-06-28 22:58 thl.data.0000000002
-rw-r--r-- 1 tungsten tungsten   9731148 2011-06-28 23:04 thl.data.0000000003
}}}

The disklog.lck is a lock file.  The THL code must get an exclusive lock on this file to write to the log.  Otherwise the THL can only read data.  The lock file is always present event if no process is using it.  If you delete the lock file by accident, the THL code will create a new one the next time you open the file.  

Data files have the form thl.data.nnnnnnnnnn, where the n's increase monotonically with each new log file.  

=== Log Record Formats === 

Log data files consist of primitive records, which in the current implementation come in three different flavors.  The primitive record formats are optimized for quick reading of header information without the need to invoke full object serialization. 

==== Header Record =====

Each data file starts with a single header record that provides a magic number, version number, and previous log file sequence number.  

|| *Name* || *Format* || *Description* ||
|| magic_number || 4 bytes, int || Log file identifier (x'C00lCAFE') ||
|| major_version || 2 bytes, short || x'0001', Major version of log format ||
|| minor_version || 2 bytes, short || x'0001', Minor version of log format || 
|| prev_seqno || 8 bytes, long ||Last seqno in previous log ||

==== Event Record ====

Event records contain a header followed by a serialized ReplDBMSEvent.   The record format is as follows.  

|| *Name*        || *Format* || *Description* ||
|| record_length || 4 bytes, int || Full length of record including record_length field ||
|| record_type   || 1 byte || Event record type identifier (x'01') ||
|| header_length || 4 bytes, unsigned int || Length of the event header.  (Not used but may be in future) ||
|| seqno         || 8 bytes, unsigned long || Log sequence number || 
|| fragno        || 2 bytes, unsigned short || Event fragment number ||
|| last_frag     || 1 byte || x'01' or x'00' where x'01' denotes last fragment of event||
|| epoch number  || 8 bytes, unsigned long || Event epoch number ||
|| source_id     || null terminated UTF-8 string || Event source ID ||
|| event_id      || null terminated UTF-8 string || Native DBMS event ID ||
|| shard_id      || null terminated UTF-8 string || Name of the shard to which this event belongs ||
|| tstamp        || 8 bytes, unsigned long || Time of commit in milliseconds since 1970 (standard Java timestamp format) ||
|| data_length   || 4 bytes unsigned int || Length of serialized event data ||
|| event         || Up to 2^32 - 1 bytes || Serialized Java object (e.g. ReplDBMSEvent) ||
|| crc_method    || 1 byte || Method used to compute CRC where x'00' means no CRC and x'01' means CRC-32 ||
|| crc           || 4 bytes, unsigned int || CRC of record excluding the CRC itself ||

==== Log Rotation Record ====
Log rotation records are written at the end of the file log file.  They are a signal to clients to switch to the next log file.  

|| *Name*        || *Format* || *Description* ||
|| record_length || 4 bytes, int || Full length of record including record_length field ||
|| record_type   || 1 byte || Log rotation record type identifier (x'02') ||
|| next_file_name || null terminated UTF-8 string || Name of the next log file ||
|| crc_method    || 1 byte || Method used to compute CRC where x'00' means no CRC and x'01' means CRC-32 ||
|| crc           || 4 bytes, unsigned int || CRC of record excluding the CRC itself ||

=== Transaction Serialization ===

DBMS transactions are stored as serialized objects of the Java ReplDBMSEvent, which Tungsten uses to represent transaction fragments in memory.   The default serialization method uses Google Protobuf, version 2.3.0. Google Protobuf uses message definition formats stored in protobuf/TungstenProtobufMessage.  We generate Java support code for serialization from this definition.  

It is also possible to use Java serialization; earlier versions of the replicator before Tungsten 1.3 used this.  However, Java serialization is extremely verbose and may not handle upgrades well.  

=== Indexing ===

= Log Management =

The THL has user-settable configuration parameters as well as a utility to read and manage log records directly.  

== Configuration ==

Current THL property settings are documented in the replication service template files.  For detailed information check out the Javadoc and source code, especially the following classes: 

[http://code.google.com/p/tungsten-replicator/source/browse/trunk/replicator/src/java/com/continuent/tungsten/replicator/thl/THL.java com.continuent.tungsten.replicator.thl.THL]

[http://code.google.com/p/tungsten-replicator/source/browse/trunk/replicator/src/java/com/continuent/tungsten/replicator/thl/log/DiskLog.java com.continuent.tungsten.replicator.thl.log.DiskLog]

The following table provides a summary of current THL class properties and their meanings.  

|| *Property* || *Description* ||
|| bufferSize || Buffer size used for reads and writes from/to storage.  This should never be less than the size of pages in persistent storage ||
|| doCheckSum || If true, enable CRC checksums on records.  Can impact log performance by up to 50% if enabled but allows unambiguous detection of log record corruption. ||
|| eventSerializer || Name of event serialization class.  Normally not changed as it defaults to protobuf serialization. || 
|| flushIntervalMillis || Interval in milliseconds for flushing writes to disk, which in turn affects how quickly log readers see them, hence the applied latency on stages that read from the log ||
|| fsyncOnFlush || If true fsync to disk when flushing.  Log writes normally just do a Java flush() command, which makes writes visible to readers but does not guarantee they are fully stored ||
|| logConnectionTimeout || Timeout for dropping log connections and freeing file descriptors.  This value is obsolete and may be removed in future. ||
|| logDir || Directory in which log files are stored.  Created automatically if it does not exist, though the parent directly of logDir must exist and be writable. ||
|| logFileRetention || Amount of time to retain log files, using a flexible time interface format.  "12h" means to preserve logs for 12 hours.  Based on the time log files are written, not the age of the transactions. ||
|| logFileSize || Maximum number of bytes to write before rotating to a new log file.  The actual lengths of files can be greater as we never rotate in the middle of fragmented transactions. ||
|| password || DBMS password where replication service catalog tables are stored ||
|| resetPeriod || How often to reset the output stream used to transmit the stream of events from a THL server.  Larger values use network bandwidth more efficiently.  ||
|| URL || JDBC URL of DBMS and schema where replication service catalog tables are stored ||
|| user || DBMS user where replication service catalog tables are stored ||


== 'thl' Utility ==

= Java APIs and Programming Model = 

== Java Class Structure == 

The classes that implement the THL are spread out over the following packages.  

|| *Package* || *Description ||
|| com.continuent.tungsten.replicator.thl || Adapts THL to pipeline interfaces (e.g., Store, Extractor, Applier) and to implement THL server ||
|| com.continuent.tungsten.replicator.thl.log || Log API and implementation classes ||
|| com.continuent.tungsten.replicator.thl.protobuf || Generated classes to implement serialization of events to/from Protobuf messages ||
|| com.continuent.tungsten.replicator.thl.serializer || Serialization adapter classes ||

The Log API in package com.continuent.tungsten.replicator.thl.log is essentially self-contained and is the main interface for testing.  There are over 50 unit test cases on the public API and individual log implementation classes.  The goal of these test cases is to ensure that the log is fast and free from errors. 

= Development = 

= Troubleshooting = 